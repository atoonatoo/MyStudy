
---

---
### 이력서 기술스택
- **JMeter**
    - **목적**
        - JMeter는 GUI로 복잡한 부하 테스트 시나리오를 설계 및 실행하기 위한 범용 테스트 도구이다.
    - **동작 원리**
        - GUI에서 Test Plan 구성
        - Thread Group이 Thread 단위로 가상 사용자 생성
        - Sampler가 요청을 실행
        - Listener가 결과를 수집 및 시각화
    - **장점**
        - 복잡한 시나리오 설계에 강함
            - 조건 분기, 반복, 컨트롤러 구조를 시각적으로 조립 가능
        - 프로토콜 지원 범위가 넓음
            - HTTP, JDBC, FTP, JMS 등 다양한 프로토콜 지원
        - 비개발자도 접근 가능
            - 코드 작성 없이 테스트 구성 가능
    - **단점**
        - 고부하 시 자원 소모 큼
            - Java Thread 모델 -> 메모리, CPU 사용량 증가
        - GUI 실행 시 성능 왜곡 위험
            - Listener, GUI 렌더링이 부하 테스트 결과에 영향
        - 자동화 및 버전 관리의 불리함
            - GUI 기반 설정은 코드 기반 도구보다 재현성이 낮음
    - **한 문장 기억 공식**
        - JMeter는 GUI와 Java Thraed를 선택해 복잡한 시나리오에 강하지만, 대규모 부하와 자동화에는 불리한 도구이다.
    - **장단점 연결 기억법**
        - 왜 시나리오가 강한가?  -> GUI + 컨트롤러 구조
        - 왜 무거운가?  -> Java Thread 기반
        - 왜 CLI 실행이 권장되는가?  -> GUI 성능 간섭 제거
        - 왜 k6와 다르게 쓰는가?  -> 목표 사용자가 다름
    
- **nginx**
    - **목적**
        - 동시 접속 문제를 해결하기 위해 이벤트 기반 비동기 구조를 선택한 웹 서버
    - **동작 원리**
        - Master Process가 설정 로드 및 Worker 관리
        - 여러 Worker Process가 요청 처리
        - 각 Worker는 이벤트 기반(event-driven)으로 요청 처리
        - 비동기 방식으로 다수의 연결을 단일 스레드에서 처리
    - **장점**
        - 매우 높은 동시 처리 성능
            - 하나의 Worker가 수천 개 연결 처리 가능
        - 낮은 메모리 사용량
            - Thread를 무한히 생성하지 않음
        - 정적 파일 처리에 매우 강함
            - 웹서버, 리버스 프록시로 탁월
    - **단점**
        - 동적 처리 로직에 부적합
            - 애플리케이션 로직 직접 처리 불가(PHP, Java 등은 외부 연동)
        - 구성 난이도
            - 설정 파일이 선언적이고 복잡하게 느껴질 수 있다.
        - Worker 수 설정 실패 시 성능 저하
            - CPU 코어 수 대비 Worker 설정 중요
    - **한 문장 기억 공식**
        - Nginx는 요청당 Thread를 생성하지 않고 이벤트 기반 비동기 모델을 선택해, 동시성에는 강하지만 애플리케이션 서버 역할은 하지 않는다.
    - **장단점 연결 기억법**
        - 왜 빠른가? -> 이벤트 기반 비동기
        - 왜 메모리를 적게 쓰는가? -> Thread 미사용
        - 왜 WAS가 필요한가? -> 로직 처리 불가
        - 왜 로드밸런서로 쓰는가? -> 연결 처리 전문
    
- **Elasticsearch**
    - **목적**
        - 대규모 데이터를 빠르게 검색, 집계, 분석하기 위한 분산 검색 엔진
        - RDB를 대체하는 것이 아니라, 텍스트 검색과 실시간 분석을 보완하기 위한 시스템
    - **동작 원리**
        - 문서를 JSON 형태로 저장
        - 문서의 텍스트 필드를 분석기(analyzer)로 토큰화
        - 토큰을 역색인(inverted index) 구조로 저장
        - 검색 시 역색인을 통해 관련 문서 ID를 빠르게 조회
        - 여러 노드에 Shard로 분산 저장 및 처리
    - **장점**
        - 매우 뛰어난 검색 성능
            - 역색인 구조로 대량 텍스트 검색에 최적
        - 수평 확장이 쉬움
            - 샤드 단위 분산으로 노드 추가만으로 확장 가능
        - 강력한 집계(aggregation) 기능
            - 로그 분석, 통계, 대시보드에 적합
        - 스키마 유연성
            - 명시적 스키마 없이도 데이터 적재 가능
    - **단점**
        - 강한 트랜잭션(ACID) 미지원
            - RDB 수준의 트랜잭션, 조인, 롤백 불가
        - 데이터 정합성 관리 부담
            - Near Real-Time 특성으로 즉시 일관성 보장 아님
        - 높은 운영 난이도
            - 메모리, 샤드 수, 인덱스 설계에 따라 성능 급변
        - 저장소로만 사용하기엔 비효율
            - 단순 CRUD 용도로는 과한 비용
    - **한 문장 기억 공식**
        - Elasticsearch는 역색인 기반으로 검색과 분석에 특화된 분산 엔진이며, 트랜잭션 처리를 목적으로 설계된 시스템은 아니다.
    - **장단점 연결 기억법**
        - 왜 검색이 빠른가? ->역색인 구조
        - 왜 확장이 쉬운가? -> 샤드 기반 분산 설계
        - 왜 트랜잭션이 약한가? -> ACID가 설계 목표가 아님
        - 왜 로그, 검색에 쓰는가? -> 검색 + 집계가 핵심 역할
      
- **Filebeat**
    - **목적**
        - 서버에서 발생하는 로그 파일을 안정적으로 수집해 중앙 시스템으로 전달하는 경량 로그 수집기
        - 로그 저장, 검색이 아니라 `전송`에 특화된 에이전트
    - **동작 원리**
        - 서버의 로그 파일을 Harvester가 tail 방식으로 읽음
        - 여러 Haverster를 Input 단위로 관리
        - 읽은 로그의 위치(offset)를 Registry에 기록
        - 로그를 Output(Elasticsearch, Logstash, Kafka 등)으로 전송
        - 장애 발생 시 Registry를 기반으로 중복 없이 재전송
    - **장점**
        - 매우 가벼움
            - CPU, 메모리 사용량이 낮아 서버 부담 적음
        - 신뢰성 있는 로그 수집
            - Offset 관리로 로그 유실, 중복 최소화
        - 다양한 출력 지원
            - Elasticsearch, Logstash, Kafka, Graylog 등 연동 가능
        - 모듈 기반 설정 제공
            - Nginx, Apache, System 로그 등 즉시 사용 가능
    - **단점**
        - 로그 처리, 분석 기능 없음
            - 파싱, 변환은 Logstash 등 외부 도구 필요
        - 검색, 저장 기능 없음
            - 단독 사용 불가
        - 복잡한 필터링에는 부적합
            - 경량 설계로 처리 로직 제한적
    - **한 문장 기억 공식**
        - Filebeat는 로그를 처리하거나 저장하지 않고, 안전하게 전달하는 데 집중한 경량 로그 수집기이다.
    - **장단점 연결 기억법**
        - 왜 가벼운가? -> 수집, 전송만 수행
        - 왜 로그 유실이 적은가? -> Registry 기반 상태 추적
        - 왜 분석이 안 되는가? -> 처리 로직을 의도적으로 배제
        - 왜 항상 다른 시스템과 함께 쓰는가? -> 전송 전용 역할
      
- **Kibana**
    - **목적**
        - Elasticsearch에 저장된 데이터를 시각화, 탐색, 분석하기 위한 웹 UI
        - 데이터 저장이나 수집이 아니라, `보여주고 이해하는 것`이 목적
    - **동작 원리**
        - Kibana가 Elasticsearch 클러스터에 연결
        - 사용자의 검색, 집계 요청을 Elasticsearch Query DSL로 변환
        - Elasticsearch에서 검색, 집계 결과 변환
        - Kibana가 결과물
            - Discover(탐색), Visualization(시각화), Dashboard(대시보드)와 같은 UI 애플리케이션을 통해 화면에 렌더링한다.
    - **장점**
        - Elasticsearch 데이터 탐색에 최적
            - Query DSL을 몰라도 UI로 검색, 필터 가능
        - 강력한 시각화 기능
            - 로그, 메트릭, 트레이스 대시보드 구성 용이
        - Elastic Stack과 깊은 통합
            - Beats, Logstash, APM과 자연스럽게 연동
        - 보안, 권한 관리 지원
            - 사용자, 역할 기반 접근 제어 가능
    - **단점**
        - Elasticsearch 없이는 의미 없음
            - 단독 사용 불가
        - 대용량, 복잡한 쿼리 시 느려질 수 있음
            - 성능은 Elasticsearch에 전적으로 의존
        - Grafana 대비 유연성 제한
            - Elasticsearch 외 데이터 소스 지원 제한적
    - **한 문장 기억 공식**
        - Kibana는 Elasticsearch 데이터를 검색, 집계, 시각화하기 위해 존재하는 전용 분석 UI이다.
    - **장단점 연결 기억법**
        - 왜 저장을 안 하는가? -> UI 전용 도구
        - 왜 Elasticsearch에 최적화됐는가? -> 데이터 소스 없음
        - 왜 단독 사용이 안 되는가? -> 데이터 소스 없음
        - 왜 Elastic Stack에서 핵심인가? -> 분석, 가시성 담당당
       
- **HikariCP**
    - **목적**
    - **동작 원리**
    - **장점**
    - **단점**
    - **한 문장 기억 공식**
    - **장단점 연결 기억법**
    
- **Redis**
    - **목적**
        - 메모리 기반으로 매우 빠른 읽기, 쓰기를 제공하는 데이터 구조 서버
        - 주 목적은 캐시, 세션 저장소, 실시간 데이터 처리
    - **동작 원리**
        - 데이터를 메모리에 Key-Value 형태로 저장
        - 값은 단순 문자열이 아니라 자료구조(String, List, Set, Hash, Sorted Set 등)로 저장
        - 기본적으로 단일 스레드 이벤트 루프로 명령 처리
        - 요청은 순차적으로 처리되어 동시성 문제 최소화
        - 필요 시 데이터를 디스크에 영속화
            - RDB 스냅샷
            - AOF(Append Only File)
    - **장점**
        - 매우 빠른 성능
            - 메모리 접근 + 단일 스레드 -> 낮은 지연(latency)
        - 풍부한 자료구조 지원
            - 카운터, 큐, 랭킹, 세션 구현에 적합
        - 원자적 연산 보장
            - 단일 스레드 처리로 race condition 최소화
        - 확장 기능 제공
            - Replication, Sentinel, Cluster 지원
    - **단점**
        - 메모리 비용이 큼
            - 대용량 데이터 저장에는 비효율적
        - 복잡한 트랜잭션에 부적합
            - RDB 수준의 조인, ACID 트랜잭션 미지원
        - 단일 스레드 한계
            - CPU 코어를 하나만 사용(대신 단순 연산을 빠르게 처리)
        - 영속성은 보조 수단
            - 디스크 기반 DB만큼의 안정성은 아님
    - **한 문장 기억 공식**
        - Redis는 메모리를 사용해 자료구조 단위 연산을 빠르게 처리하는 단일 스레드 기반 데이터 저장소이다.
    - **장단점 연결 기억법**
        - 왜 빠른가? -> 메모리 기반 + 단일 스레드
        - 왜 동시성 문제가 적은가? -> 명령 순차 처리
        - 왜 캐시에 쓰는가? -> 낮은 지연, 단순 접근
        - 왜 주 DB로 쓰기 어려운가? -> 메모리 비용 + 트랜잭션 한계
    
- **Spring Security**
    - **목적**
        - Spring 기반 애플리케이션에 인증(Authentication)과 인가(Authorization)를 제공하는 보안 프레임워크
        - 로그인 처리, 접근 제어, 공격 방어를 애플리케이션 코드와 분리하는 것이 목적
    - **동작 원리**
        - 클라이언트 요청이 Security Filter Chain에 진입
        - 여러 Security Filter가 순차적으로 요청 검사((인증 필터, 인가 필터, 예외 처리 필터 등)
        - 인증 시 `AuthenticationManager`가 인증 처리 내부적으로 `AuthenticationProvider` 사용
        - 인증 성공 시 `SecurityContext`에 인증 정보 저장
        - 이후 요청마다 `SecurityContext`를 기준으로 접근 허용/차단 결정정
    - **장점**
        - 강력한 보안 기본값 제공
            - CSRF, XSS, Session, Fixation
        - 인증, 인가 로직 표준화
            - 직접 구현 대비 보안 실수 가능성 감소
        - 다양한 인증 방식 지원
            - Form, Login, HTTP Basic
            - JWT, OAuth2, OIDC 등
        - Spring 생태계와 완벽한 통합
            - Controller, Method, URL 단위 접근 제어 가능
    - **단점**
        - 초기 학습 난이도 높음
            - Filter Chain, Context 구조 이해 필요
        - 설정이 복잡해 보일 수 있음
            - 자동 설정과 커스터마이징 경계가 불명확하게 느껴질 수 있음
        - 잘못 설정하면 의도치 않은 보안 허점 발생
            - 허용/차단 규칙 순서 중요
    - **한 문장 기억 공식**
        - Spring Security는 필터 체인을 기반으로 인증과 인가를 표준화해 제공하는 Spring 전용 보안 프레임워크이다.
    - **장단점 연결 기억법**
    - 왜 보안 기본값이 강한가? -> Filter Chain 기본 적용
    - 왜 커스터마이징이 어려운가? -> 구조가 추상화되어 있으
    - 왜 Spring에서 사실상 표준인가? -> IoC, MVC와 깊은 통합
    - 왜 직접 구현보다 안전한가 ? -> 검증된 보안 패턴 내장
    
- **token**
    - **목적**
    - **동작 원리**
    - **장점**
    - **단점**
    - **한 문장 기억 공식**
    - **장단점 연결 기억법**
    
- **도메인 모델 패턴**
    - **목적**
    - **동작 원리**
    - **장점**
    - **단점**
    - **한 문장 기억 공식**
    - **장단점 연결 기억법**
    
- **Repository + QueryDSL**
    - **목적**
    - **동작 원리**
    - **장점**
    - **단점**
    - **한 문장 기억 공식**
    - **장단점 연결 기억법**
    
- **DTO 기반**
    - **목적**
    - **동작 원리**
    - **장점**
    - **단점**
    - **한 문장 기억 공식**
    - **장단점 연결 기억법**
    
- **OpenAI API**
    - **목적**
    - **동작 원리**
    - **장점**
    - **단점**
    - **한 문장 기억 공식**
    - **장단점 연결 기억법**

### CS
- 데이터그램
    - 독립적인 봉투
        - 데이터 그램은 수신 측과 사전 연결 없이, 목적지 주소 등 전송에 필요한 모든 정보를 스스로 담고 있는 독립적인 데이터 단위이다.
    - 비연결성
        - 데이터를 보내기 전에 handshake를 거치지 않고 일단 목적지를 향해 던지는 방식
    - 비신뢰성
        - 데이터가 순서대로 도착하는지, 중간에 유실되었는지 확인하지 않지만 전송 속도가 매우 빠름

- Best-effort delivery
    - 책임 회피형 전달
        - 네트워크가 데이터를 목적지까지 전달하기 위해 최선을 다하지만, 도착 여부나 데이터의 상태를 보장하지 않는 방식
    - 단순한 메커니즘
        - 복잡한 에러 복구나 재전송 로직이 없어 구조가 단순하며, 네트워크 장비(라우터 등)부하를 최소화함
    - 상위 계층의 몫
        - 전송 중에 데이터가 사라지거나 순서가 뒤바뀌어도 네트워크(IP계층)는 상관하지 않으며, 이 문제를 해결하려면 상위 계층(TCP 등)에서 별도의 로직을 처리해야 한다. 

- Parsing
    - 일련의 문자열을 분석하여, 컴퓨터가 이해하고 처리하기 쉬운 구조적 데이터로 변환하는 과정을 의미
    - 이 작업을 수행하는 프로그램을 Parser라고 부르며, 컴파일러나 인터프리터의 핵심 구성 요소 중 하나이다.

- QUIC
    - UPD를 기반으로 동작하면서, 그 위에 TCP의 신뢰성 전송 기능과  TLS의 보안 기능을 직접 구현한 계층 결합형 프로토콜이다.
    - HTPP/3의 근간이 되는 기술

- 흐름 제어, 혼잡 제어, 오류 제어
    - 흐름 제어
        - 송신자가 수신자의 처리 속도를 넘어서지 않게 조절하는 것
        - 목적
            - 송신 측이 데이터를 너무 빨리 보내서 수신 측의 Buffer가 넘치는(Overflow) 것을 방지
        - 대상
            - 송신자(Sender)와 수신자(Receiver) 사이의 1:1 관계
        - 주요 기법
            - Stop-and-Wait
                - 패킷 하나를 보내고 확인 응답(ACK)을 받을 때까지 기다린 후 다음 패킷을 보냄
            - Silding WIndow
                - 수신 측이 한 번에 받을 수 있는 데이터 양(Window Size)을 알려주면, 송신 측은 ACK 없이도 그만큼 데이터를 연속해서 보낼 수 있다.
    - 혼잡 제어
        - 네트워크 망의 데이터 처리 능력을 넘어서지 않게 조절하는 것
        - 목적
            - 네트워크 내의 라우터나 스위치가 감당할 수 없을 정도로 많은 데이터가 몰려 패킷이 지연되거나 유실되는 것을 방지
        - 대상
            - 송신자와 수신자뿐만 아니라, 그 사이클 잇는 네트워크 전체(Router 등)를 고려한다.
        - 주요 기법
            - Slow Start
                - 전송 속도를 아주 조금씩(지수적으로) 늘려가며 네트워크 상태를 확인한다.
            - Congestion Avoidance
                - 혼잡이 예상되는 지점부터 속도를 선형적으로 완만하게 올린다.
            - Fast Retransmit / Fast Recovery
                - 패킷 손실이 감지되면 즉시 전송 속도를 줄이고 빠르게 복구한다.
    - 오류 제어
        - 데이터가 꺠지거나 유실되었을 때 이를 탐지하고 복구하는 것
        - 목적
            - 전송된 데이터가 전송 전과 동일하다는 것을 보장
        - 주요 기법
            - Checksum
                - 데이터 전송 전후의 합계를 비교하여 데이터 ㅅ혼상 여부 확인
            - ARQ(Automatic Repeat Request)
                - 오류가 발생했거나 패킷이 유실되었을 때 재전송을 요청

- 멱등성
    - 연산을 여러 번 적용하더라도 결과가 달라지지 않는 성질을 의미

- CORS(Cross-Origin Resource Sharing) 

- 프리플라이트(Preflight)