---
title: undefined
type: Resume
director: My
date: 2025-10-20
tags:
  - programing
  - employment
  - resume
---

## 1. 부하 테스트 설계와 도구 선정

프로젝트의 안정성과 확장성을 검증하기 위해 실제 사용자 행위를 모사한 복합 시나리오 기반 부하 테스트를 설계했습니다. Spring Security 로그인부터 JWT 및 리프레시 토큰 발급, 무작위 플레이리스트 조회, 내부 동영상 반복 조회로 이어지는 단계별 API 흐름을 구성하고, 요청 간 데이터 의존성과 인증 연속성을 검증했습니다.

k6, Locust, nGrinder 등 다양한 부하 테스트 도구를 검토한 결과, Apache JMeter를 선택했습니다. 다른 도구들은 모두 스크립트를 직접 작성하는 코드 기반 방식이지만, JMeter는 테스트 플랜 내의 JSON Extractor, Header Manager, CSV Data Set Config, ForEach Controller 등 다양한 요소를 통해 로그인, 토큰 추출, 데이터 주입, 반복 호출 과정을 시각적으로 구성할 수 있었습니다.

이를 통해 복잡한 인증 시나리오도 코드 작성 없이 자동화할 수 있었으며, 시간적 비용을 크게 절감했습니다. 또한 동일한 구성 방식을 활용해 추후 새로운 테스트 시나리오를 손쉽게 확장할 수 있어 유지보수 측면에서도 유리했습니다.

이를 기반으로 실제 사용자 2만 명 규모의 동시 부하 환경을 재현하고, 로그인 처리량, JWT 인증 속도, 응답 시간, 에러율을 분석해 시스템 병목 구간을 검증했습니다. 테스트 결과, 로그인 요청 로직에서 높은 병목 현상이 발생했고, 단일 서버 구조의 한계와 분산 환경 도입 필요성을 확인했습니다. 또한 스택트레이스 에러 로그가 출력되지 않는 문제와 캐싱 부재로 인한 데이터베이스 부하를 발견하여, 로깅 개선과 Redis 캐싱 도입의 필요성을 도출했습니다.

---

## 2. Nginx 기반 로드 밸런싱 및 트래픽 제어

부하 테스트 결과, 로그인 요청의 응답 속도가 심각하게 지연되는 현상이 확인되었습니다. 이는 단일 서버로는 대량의 트래픽을 감당하기 어렵다는 사실을 보여주었습니다. 단순히 요청을 여러 서버로 나누는 것만으로는 충분하지 않았으며, 인증 요청의 폭증을 제어하고 병목의 근본 원인을 완화할 수 있는 구조가 필요했습니다.

여러 로드밸런서 후보 중 Nginx를 선택한 이유는 이러한 요구를 동시에 충족할 수 있었기 때문입니다. Nginx는 HTTP 계층에서 요청 큐잉, keep-alive, 헤더 정규화, rate-limit 등 트래픽 제어 기능을 기본적으로 제공하며, 업스트림 설정만으로도 부하 분산 정책을 세밀하게 조정할 수 있습니다.

또한 요청 시간, 응답 시간, 상태 코드 등 세부 로그 필드를 지원해 병목 구간을 정밀하게 분석할 수 있었고, 기존 서버 환경에 쉽게 통합되어 배포 부담이 적었습니다. HAProxy는 성능은 우수했지만 설정이 복잡하고, AWS ALB는 비용과 종속성이 높았으며, Traefik은 컨테이너 환경 중심이라 불필요한 구성이 많았습니다. 결과적으로 Nginx는 트래픽 분산, 성능 개선, 운영 효율성을 동시에 확보할 수 있었기에 선택했습니다.

Nginx 도입 이후, 로그인 요청의 처리 속도와 전체 응답 시간이 크게 개선되었습니다. 서버 간 트래픽이 균등하게 분산되면서 특정 서버에 과부하가 집중되는 현상이 사라졌고, 병목 구간에서 발생하던 응답 지연도 안정적으로 해소되었습니다.

rate-limit 기능을 통해 인증 요청 폭주 시에도 서비스 전체가 멈추지 않고 일정 수준의 응답 품질을 유지할 수 있었으며, keep-alive와 요청 큐잉으로 백엔드 연결 재사용률이 높아져 CPU 사용량과 네트워크 부하가 감소했습니다. 그러나 응답 지연이 대폭 감소한 반면, 분산 환경에서의 세션 처리 불일치와 일시적 연결 실패로 인해 에러율이 일시적으로 약 40%까지 증가했습니다.

Nginx가 생성한 상세 로그와 EFK 스택의 시각화 분석을 통해 원인을 추적한 결과, 데이터베이스 커넥션 풀 고갈 및 세션 동기화 문제로 인한 오류임을 확인했습니다. 이후 커넥션 풀 용량 조정과 세션 관리 개선을 통해 에러율은 안정적으로 회복되었으며, 트래픽 분산 효과와 함께 전체 서비스의 응답 성능이 크게 향상되었습니다.

---

## 3. 로그 수집 및 분석 체계

### 3.1 대용량 로그 검색 및 집계

부하 테스트 과정에서 로그인 병목 현상의 원인을 추적하기 위해 로그를 분석했으나 스택트레이스가 출력되지 않아 오류를 집중적으로 파악하기 어려웠습니다. 로드밸런서 환경에서 서버별 로그가 분리되어 있어 직접 탐색하는 방식은 시간이 많이 걸리고 누락 위험이 높아 매우 비효율적이었습니다.

이를 해결하기 위해 여러 로그 분석 도구(Loki, Graylog, OpenSearch 등)를 검토했지만, Elasticsearch만이 역색인 구조를 통해 대규모 로그 본문 전체를 신속하게 검색하면서도 필드 단위 집계와 필터링을 동시에 수행할 수 있었습니다.

Loki는 라벨 인덱싱 특성상 스택트레이스 탐색에 한계가 있었고, OpenSearch와 Graylog는 안정성과 운영 지원 측면에서 완성도가 낮았습니다. 반면 Elasticsearch는 즉시 적용 가능한 인덱스 정책과 집계 기능을 갖추고 있어 로그 탐색 정확도, 속도, 운영 효율성 면에서 모든 요구 조건을 충족했습니다. 결국 로그인 병목 구간의 원인을 빠르고 정확하게 규명하고, 다중 서버 환경에서도 오류 추적의 신뢰성과 분석 효율성을 높이기 위해 반드시 필요한 선택이었습니다.

### 3.2 경량 수집기와 신뢰성 전송

Elasticsearch를 통해 로그 분석 효율을 확보했지만, 다중 서버 환경에서는 각 인스턴스의 로그를 중앙 저장소로 안정적으로 전달할 수 있는 수집기가 필요했습니다. 단순 스크립트 전송 방식은 누락과 중복이 잦고, 전송 실패 시 복구가 어려워 실시간 분석에 적합하지 않았습니다.

이를 해결하기 위해 여러 수집기 후보(Fluent Bit, Vector, rsyslog, Logstash Forwarder 등)를 검토했으나, Filebeat이 가장 안정적이면서 Elasticsearch와의 호환성이 뛰어났습니다. Fluent Bit과 Vector는 설정이 복잡해 운영 리스크가 높았고, rsyslog는 시스템 로그 중심이라 애플리케이션 로그 처리에 한계가 있었습니다.

반면 Filebeat은 경량 에이전트로 CPU·메모리 점유율이 낮고, 로그 파일 변화를 실시간 감지하여 전송 중 장애가 발생해도 자동으로 재시도해 데이터 손실을 방지합니다. 또한 Elasticsearch로 직접 전송되어 인덱싱이 자동화되며, 서버별 로그 경로와 포맷 관리도 간단히 구성할 수 있었습니다. 이를 통해 다중 서버 로그를 실시간으로 중앙화하고, 안정적이고 신뢰성 높은 분석 체계를 완성했습니다.

### 3.3 실시간 시각화 및 알림

Elasticsearch로 로그 중앙화와 검색 체계를 구축한 뒤, 수집된 데이터를 시각적으로 분석하기 위해 Kibana를 도입했습니다. 다양한 시각화 도구 중에서 Kibana는 Elasticsearch와의 연동이 가장 자연스럽고, 로그 본문을 그대로 검색하며 실시간 필터링까지 지원해 분석 효율이 뛰어났습니다. Grafana는 시각적 표현력은 우수했지만 로그 세부 탐색에는 제약이 있었고, OpenSearch Dashboards는 버전 안정성과 기능 완성도 측면에서 한계가 있었습니다.

Graylog는 단순 조회 위주라 대규모 로그 시각화에 적합하지 않았으며, Datadog은 데이터 사용량 증가에 따라 비용이 크게 상승했습니다. Kibana는 시간, 서버, API별 필터링과 에러율·응답 시간의 시각적 집계를 지원해 로그인 실패율, JWT 갱신 지연, 서버별 부하 같은 주요 지표를 실시간으로 파악할 수 있었습니다. 또한 알림 기능을 통해 오류 발생 시점을 자동 감지하여 대응 속도를 높였으며, 결과적으로 Kibana는 로그 데이터에서 병목 원인을 빠르게 식별하고, 실시간 운영 안정성을 확보하는 핵심 도구로 기능했습니다.

## 3.4 EFK 통합: 수집 → 색인 → 시각화

Elasticsearch, Filebeat, Kibana를 연동한 EFK 스택을 구축하여 로그의 수집부터 분석까지 하나의 흐름으로 통합했습니다. Filebeat이 각 서버의 로그를 안정적으로 수집하고, Elasticsearch가 대용량 로그 본문을 빠르게 색인 및 검색하며, Kibana가 그 결과를 시각화해 오류 패턴을 직관적으로 보여주는 구조입니다.

이를 통해 로그를 개별적으로 확인하던 비효율적인 과정을 제거하고, 다중 서버 환경에서도 로그 손실 없이 실시간 분석이 가능했습니다. 특히 EFK 스택을 활용해 클라이언트 단에서부터 계층적으로 하위 레이어로 추적하며 분석함으로써, Nginx 단에서 로그인 병목 현상의 원인이 되는 유의미한 스택트레이스를 빠르게 발견하고 식별할 수 있었습니다. 결과적으로 EFK 스택은 문제 진단 시간을 단축하고, 서비스의 안정성과 관측 체계를 한층 강화하는 핵심 인프라로 자리 잡았습니다.

---

## 4. HikariCP 커넥션 튜닝

로그 수집 결과, DB 연결 풀 고갈과 누수 의심 로그가 발견되어 병목의 원인이 애플리케이션이 아닌 DB 단임이 확인되었습니다. 로그인 요청이 순간적으로 몰릴 때도 연결을 빠르게 빌려주고, 누수를 감지하며, 장애 시 복구 지연을 최소화할 수 있는 커넥션 풀 관리가 필요했습니다.

이 요구를 충족하기 위해 HikariCP, Apache DBCP2, Tomcat JDBC Pool, c3p0 등을 비교 분석했습니다. HikariCP는 내부 락 경합이 적어 연결 획득 지연이 매우 짧고, connectionTimeout과 leakDetectionThreshold를 통해 누수나 장애를 신속히 감지할 수 있습니다.

또한 idleTimeout과 maxLifetime으로 불필요한 연결을 자동 정리해 풀 고갈을 방지하고, 실시간 지표를 통해 운영 중에도 안정적으로 튜닝이 가능합니다. Apache DBCP2는 검증 쿼리로 인한 추가 지연이 존재하고, Tomcat Pool은 관측 기능이 단순하며, c3p0는 구조적 오버헤드가 높았습니다. HikariCP는 이러한 제약을 최소화하면서도 고부하 로그인 환경에서 빠르고 안정적인 연결 관리가 가능했기에 선택했습니다.

HikariCP 도입 이후 응답 지연 시간과 에러율이 모두 감소하며 전반적인 성능이 개선되었습니다. 다만 여전히 사용자 체감 속도 측면에서는 만족스러운 수준에 이르지 못해, 이후 캐싱과 쿼리 최적화를 포함한 추가 개선 방안을 모색했습니다.

---

## 5. Redis 캐싱 도입(세션, 토큰, TTL)

응답 지연과 에러율은 줄었지만 사용자 체감 속도는 여전히 부족했습니다. 로그인과 반복 조회 요청이 집중되는 구조였기에, 동일한 데이터를 매번 DB에서 불러오는 방식으로는 한계가 있었습니다.

이를 개선하기 위해 다중 서버 간에도 빠르고 일관된 데이터 접근이 가능한 인메모리 캐시를 도입했습니다. 검토 과정에서 Redis는 단순 캐싱을 넘어 TTL 관리, 세션 유지, 토큰 블랙리스트와 같은 전역 상태 제어까지 지원해 로그인 서비스 구조에 적합했습니다.

Memcached는 속도는 빠르지만 단순 키-값 저장만 가능했고, Caffeine은 각 서버 내부에서만 작동해 분산 환경에서는 캐시 불일치가 발생할 수 있었습니다. Hazelcast는 기능은 풍부했으나 운영 부담이 컸습니다. Redis는 다양한 데이터 구조를 지원하며 클러스터 구성과 장애 복구가 용이해, 사용자 인증 및 조회 요청 처리의 응답 지연 시간과 에러율이 대폭 감소했습니다.

---

## 6. 사용자 정보 관리 및 사용자 인증 및 인가
  
프로젝트의 로그인 구조는 JWT 기반 API 인증과 세션 기반 관리 화면이 병행되는 형태였기에, 인증·인가를 통합 관리할 수 있는 Spring Security를 도입했습니다. SecurityFilterChain을 다중 구성하여 URL 단위로 세밀한 보안 정책을 분리하고, AuthenticationEntryPoint 및 AccessDeniedHandler를 통해 예외 처리와 로깅을 표준화했습니다. JWT 리소스 서버를 구성하여 키 회전(JWK), 권한 매핑, 리프레시 토큰 롤링 정책을 안정적으로 적용했으며, Redis를 통한 세션 TTL·토큰 블랙리스트 관리에도 자연스럽게 결합되었습니다.

JWT를 사용한 이유는 서비스 구조가 REST API 중심의 **무상태(Stateless)** 환경이었기 때문입니다. 세션이나 쿠키 기반 인증은 서버에 상태 정보를 저장해야 하므로, 다중 서버·로드밸런싱 환경에서는 세션 동기화 비용이 커지고 확장성이 떨어집니다. 반면 JWT는 인증 정보를 자체적으로 포함해 별도의 세션 저장소 없이 인증이 가능하며, 토큰 만료·갱신 시점을 명확히 제어할 수 있습니다. 또한 Redis와 함께 사용하면 블랙리스트 관리나 즉시 무효화 같은 보완 정책도 유연하게 적용할 수 있습니다.  
Apache Shiro는 경량하지만 세션 중심 구조로 JWT 확장이 어렵고, pac4j는 설정 복잡도가 높았습니다. Keycloak은 강력한 IdP 기능을 제공하지만 외부 서버 운영과 유지보수 비용이 과도했습니다. Spring Security는 스프링 부트와 완전하게 통합되어, 무상태/상태 혼용, 메서드 보안, 테스트 자동화까지 하나의 체계 안에서 구현할 수 있었습니다. 그 결과 인증 흐름의 일관성과 확장성, 그리고 유지보수 효율성을 모두 달성하며, 향후 사용자 증가 및 정책 변경에도 안정적으로 대응할 수 있었습니다.
  
---

## 7. 플레이리스트

---

## 8. ChatGPT Open API


---

## 9. 설계 및 구현 그리고 시나리오 작성

---

부하 테스트 도구 후보
JMeter, k6, Locust, nGrinder

로그 수집기 후보
Elasticsearch, OpenSearch, Loki, Graylog, ClickHouse, Splunk, Datadog, New Relic

로그 수집 에이전트(수집기)
Filebeat, Fluent Bit, Vector, rsyslog, Logstash Forwarder

시각화·모니터링 도구
Kibana, Grafana, OpenSearch Dashboards, Graylog Web UI, Datadog Dashboard

로드밸런서
HAProxy, AWS ALB, Traefik

커넥션 풀 관리
Apache DBCP2, Tomcat JDBC Pool, c3p0

캐싱
Memcached, Caffeine, Hazelcast

