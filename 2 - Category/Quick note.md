
---
- [[0 Home]]
---

- 병목지점이란 무엇인가
	- 전체 데이터의 흐름 중 가장 느린 구간을 의미?
		- 라우터 처리 능력 부족
			- 여러 장비가 연결되어 있지만 라우터가 데이터를 빠르게 전달하지 못함.
		- 서버 네트워크 카드 속도 제한
			- 서버는 빠른데 NIC가 100Mbps만 지원하면 병목
		- 스위치 포트 간 속도 차이
			- 기가비트 장비끼리 연결되었지만, 중간에 100Mbps 스위치가 있음.
		- 백엔드 서버의 느린 DB 응답
			- 클라이언트 요청은 빠르게 도착했지만, DB 응답이 느려 전체 트래픽 지연 발생.
		- ISP 회선 대역폭 한계
			- 내부망은 빠르지만, 인터넷 회선 자체가 느림.
			  
	- 중요한 이유?
		- 병목을 해결하지 않으면 하드웨어를 아무리 업그레이드해도 전체 성능 향상이 제한된다.
		- 정확한 병목 지점 파악 없이 무작정 업그레이드하면 비효율적인 낭비가 발생한다.
		- 성능 테스트를 하고 문제를 해결하기위해서는 정확한 병목지점을 보고 이해하며 원인을 좁혀갈 수 있는 능력이 필요하다.
		  
	- 탐지 방법?
		- 모니터링 툴 활용
			- 서버/네트워크 모니터링 도구를 사용해 어느 구간에서 트래픽 지연이 생기는지 확인한다.
			- wireshark - 패킷 수준 분석
			- iftop, nload - 리눅스에서 실시간 트래픽 확인
			- Netdata, Zabbix, Prometheus + Grafana - 종합적인 모니터링
			- Ping, Traceroute, mtr - 경로 추적과 지연시간 확인
		- 네트워크 구간별 테스트
			- 클라이언트 <-> 스위치 <-> 라우터 <-> 서버 간의 각 지점에 대해 ping, iperf, traceroute를 통해 응답속도와 패킷 손실율을 확인한다.
		- 서버 로그 분석
			- 서버 응답이 느릴 경우, WAS 및 DB 로그를 통해 I/O 지연, DB 쿼리 속도 등 병목 원인을 찾아야 한다.
			  
	- 병목 해결 방법?
		- 하드웨어 업그레이드
		- 트래픽 분산
			- 로드밸런서를 도입해 특정 서버나 링크에 집중되는 트래픽을 여러 서버로 분산
				- 예시 - Nginx, HAProxy, L4 스위치 등
		- Qos 설정 (Quality of Service)
			- 중요 트래픽에 우선 순위를 부여해 트래픽 혼잡 시에도 필수 서비스는 원활히 동작하도록 설정.
		- 네트워크 구성 최적화
			- 허브  -> 스위치 구조로 변경 (허브는 트래픽 전체를 브로드 캐스팅 하므로 병목 초래)
		- 서버/DB 성능 튜닝
			- 네트워크 병목이 아닌 애플리케이션 병목일 경우
				- DB 인덱스 추가
				- 쿼리 최적화
				- 비동기 처리 도입
				- GC 튜닝 (가장 최후의 수단)
				  
	- 병목 탐지시 체크리스트
		- CPU 사용률
			- top, htop, 모니터링 툴
		- 네트워크 대역폭 사용률
			- iftop, vnstat, 라우터 모니터링
		- 패킷 손실률
			- ping, mtr, traceroute
		- 응답 시간
			- curl, Jmter, 로그 응답시간
		- DB 쿼리 성능
			- slow query log, 실행계획(EXPLAIN)
	
- nginx란 무엇인가
	- nginx는 고성능 웹서버이자 오픈 소스 웹 서버이다.
	- 등장 배경
		- 기존 대표적인 웹서버였던 Apache HTTP Server는 스레드 기반 동기 처리 방식이었다. 이는 동시 접속자 수가 많아질수록 성능이 급격하게 저하되는 문제를 가지고 있었고, 시스템 자원을 많이 소비했다. 당시 웹서버가 C10K 문제를 처리하는데 한계를 드러내자 이에 대응하기 위해 Nginx가 등장하게 된다.
		- C10K 문제
			- `Client 10,000`의 약자
			- 하나의 서버에서 10,000명 이상의 클라이언트의 동시 연결을 처리하려고 할 때 생기는 성능 문제를 의미
			- 기존 웹서버들은 클라이언트 연결 하나당 하나의 스레드를 생성하는 구조였기 때문에, 동시 접속 수가 증가하면 CPU 및 메모리 자원이 급격히 소모되었다.
			- 이를 해결하기 위해 Nginx는 이벤트 기반 비동기 I/O 모델을 채택하여 가볍고 빠른 성능을 구현했다.
	- 주요 역할
		- 웹서버
			- HTML, CSS, JS 등 정적 파일을 매우 빠르게 제공
				- HTML, CSS, JS는 이미 완성된 형태로 저장되어 있기떄문에 요청이 오면 그냥 읽어서 보내기만 하면된다.
				- 복잡함 로직 처리, DB 조회, 랜더링 X
		- 리버스 프록시
		- 로드 밸런싱 
		- HTTP 캐시를 빠르고 효율적으로 처리
			- 정적 콘텐츠 고속 전송 목적으로 설계됨
			- 디스크 캐시 + 메모리 캐시 이중 지원
			- `proxy_cache` 등 캐시 지시어 제공
			- 이벤트 기반 처리(Event-driven I/O)
				- 동시 수천 요청도 스레드 생성 없이 처리 가능
				- 캐시된 응답도 매우 낮은 리소스 사용량으로 전달 가능
	- nginx를 왜 사용하는 이유
		- 일관된 고성능
			- 10년 이상 검증된 고성능 reverse proxy & static proxy server 실사용 기준에서 Node.js나 Apache보다 일관된 성능 유지
		- 설정 단순 + 강력한 기능
			- proxy_pass, load balancing, caching, gzip, SSL, rate, limiting 등 대부분의 웹 요구를 간단한 conf 한두줄로 구성 가능
		- 멀티 역할 기능
			- 웹서버 + 리버스 프록시 + 캐시 서버 + API 게이트웨이 역할까지 모두 가능.
			- 전용 장비 없어도 아키텍쳐 설계 간결화 가능
		- 높은 경량성
			- Node.js도 비동기지만, 런타임 비용이 크다.
			- Nginx는 C로 작성되어 런타임 오버헤드가 극히 낮다.
		- 프론트단 최적화에 최적
			- HTML, CSS, JS, 이미지같은 정적 파일을 매우 빠르게 처리가능
			- 정적 파일 처리에 있어선 거의 독보적이다.
		- 폭넓은 채택과 생태계
			- 전 세계 상위 웹사이트 중 과반이 NGINX 사용 문서 많고 튜토리얼 많고, 문제 해결도 쉬움
	- 간단한 nginx 동작 구조
		- Master-Worker 프로세스 모델로 구성
		- Master Process
			- 설정 파일을 읽고, Worker Process를 관리
		- Worker Process 
			- 클라이언트의 요청을 처리하며, 각 Worker는 독립적으로 동작
	- 웹 서버란 무엇인가?
		- HTTP 요청을 받고, HTTP 응답을 제공하는 서버
		- 주기능은 정적 파일 제공, 백엔드 전달, 보안, 로깅
		- 정적파일이면 직접 응답하고 동적 요청이면 백엔드 서버에 전달
		- 응답 결과를 HTTP 응답 형태로 사용자에게 전달
		- 웹서버 vs WAS
			- 웹서버
				- 정적 콘텐츠 제공, 리버스 프록시
				- Nginx, Apache HTTP Server
			- WAS
				- 동적 콘텐츠 처리 (java, Python 등)
					- 프로그램 실행환경과 DB 접속 기능 제공
					- 여러 개의 트랜잭션(논리적인 작업 단위) 관리 기능
					- 업무를 처리하는 비즈니스 로직 수행
				- Tomcat, Spring Boot, Flask, Django
			- 보통은 웹서버 + WAS 구조로 함께 사용
			- 웹서버가 요청을 받고, 동적 처리는 WAS에 넘긴다.
	- 웹서버와 WAS를 구분하는 이유
		- 웹서버가 필요한 이유?
			- 정적 컨텐츠만 처리하도록 기능을 분배하여 서버의 부담을 줄인다.
		- WAS가 필요한 이유?
			- WAS를 통해 요청에 맞는 데이터를 DB에 가져와서 비즈니스 로직에 맞게 그때 그때 결과를 만들어서 제공함으로써 자원을 효율적으로 사용할 수 있다.
		- 그렇다면 WAS가 웹서버의 기능도 모두 수행하면 되지 않을까?
			- 기능을 분리하여 서버 부하 방지
				- WAS는 DB 조회, 다양한 로직을 처리하느라 바쁘기 때문에 단순한 정적 컨텐츠는, 웹서버로 빠르게 클라이언트에 제공하는 것이 좋다.
				- WAS는 기본적으로 동적 컨텐츠를 제공하기 위한 서버이다.
			- 물리적인 분리하여 보안 강화
				- SSL에 대한 암복호화 처리에 웹서버를 사용
			- 여러 대의 WAS를 연결 가능
				- Load Balancing을 위해서 웹서버를 사용
				- fail over(장애 극복), fail back 처리에 유리
				- 특히 대용량 어플리케이션의 경우 (여러개의 서버 사용), 웹서버와 WAS를 분리하여 무중단 운영을 위한 장애 극복에 쉽게 대응할 수 있다.
				- 예를들어, 앞 단의 Web Server에서 오류가 발생한 WAS를 이용하지 못하도록 한후 WAS를 재시작함으로써 사용자는 오류를 느끼지 못하고 이용할 수 있다.
			- 여러 웹 어플리케이션 서비스 가능
				- 예시 - 하나의 서버에서 PHP Application, Java Application을 함께 사용하는 경우
			- 기타 접근 허용 IP 관리, 2대 이상 서버에서의 세션 관리 등도 웹서버에서 처리면 효율적이다.
			- 즉, 자원 이용의 효율성 및 장애 극복, 배포 및 유지보수의 편의성을 위해서 웹서버와 WAS를 분리
	- 프록시 서버란 무엇인가?
		- 클라이언트와 실제 서버 사이에서 중개 역할 하는 서버
		- 왜 프록시 서버를 사용하는가?
		- 보안 강화
			- 클라이언트와 실제 서버 간의 IP  주소를 숨겨 프라이버시 보호
		- 캐싱을 통한 성능 향상
			- 자주 요청되는 데이터를 저장해 빠르게 응답
		- 접근 제어
			- 특정 사이트 차단, 내부망 보호 등
		- IP 우회
			- 다른 지역 IP로 접속하여 차단 우회
		- 로드 밸런싱
			- 여러 서버에 트래픽 분산 가능
	- 프록시 서버 종류
		- 정방향 프록시(Forward Proxy)
			- 클라이언트 앞단에 위치
			- 클라이언트에서 요청할 때 직접 요청하는 것이 아닌 프록시서버로 거치는 방식
				- 사용자의 프라이버시 보호
		- 역방향 프록시(Reverse Proxy)
			- 서버 앞단에 위치
			- 서버에서 클라이언트 직접 데이터를 전달하지 않고 프록시 서버를 거치는 방식
				- nginx, apache 등 웹서버에서 사용
		- 오픈 프록시
			- 누구나 접근 가능한 프록시 (보안 취약점 우려)
	
- DB index란 무엇인가?
	- ![[Pasted image 20250601190104.png]]
	- 추가적인 쓰기 작업과 저장 공간을 활용하여 데이터베이스 테이블의 검색 속도를 향상 시키기위한 자료 구조이다.
	- 데이터베이스에서 원하는 데이터를 더 빠르게 찾기 위해 사용하는 자료구조이다.
	- 책의 목차처럼, 데이터를 빠르게 찾기 위한 키 목록
		- 책에서 특정 단어를 찾으려면 목차나, 색인(index)를 보고 찾듯이, DB에서도 마찬가지로, 전체 테이블을 다 뒤지는 대신 인덱스를 통해 빠르게 위치를 찾아가는 방식이다.
	- 인덱스를 활용하면 데이터를 조회하는 SELECT 외에도 UPDATE, DELETE의 성능이 함께 향상된다. 그러한 이유는 해당 연산을 수행하려면 해당 대상을 조회해야만 작업을 할 수 있기 때문이다.
	- `UPDATE USER SET NAME = 'MangKyu' WHERE NAME = 'Mang';`
		- Mang이라는 이름을 업데이트 해주기 위해서는 Mang을 조회해야 한다.
	- 인덱스가 없는 경우
		- `SELECT * FROM users WHERE email = 'a@example.com';`
		- 전체 테이블을 한 줄씩 읽으며 비교 -> 느림
	- 인덱스가 있는 경우
		- `email` 컬럼에 인덱스를 걸면 인덱스에서 먼저 위치를 찾고, 그 위치의 데이터를 바로 조회 -> 매우 빠름
	- 사용 예시
		- email 컬럼에 인덱스 생성
		- `CREATE INDEX idx_email ON users(email);
	- 인덱스의 자료구조
		- Hash Table
			- 정확한 값 검색에 빠름, 범위 검색은 불가능
			- 해시 테이블 기반의 DB 인덱스는 (데이터=컬럼의 값, 데이터의 위치)를 (Key, Value)로 사용하여 컬럼의 값으로 생성된 해시를 통해 인덱스를 구현하였다. 해시 테이블의 시간복잡도는 O(1)이며 매우 빠른 검색을 지원한다. 하지만 DB 인덱스에서 해시 테이블이 사용되는 경우는 제한적인데, 그러한 이유는 해시가 등호(=) 연산에만 특화되었기 때문이다. 해시 함수는 값이 1이라도 달라지면 완전히 다른 해시 값을 생성하는데, 이러한 특성에 의해 부등호 연산(>,<)이 자주 사용되는 데이터베이스 검색을 위해서는 해시 테이블이 적합하지 않다. 즉, 예를들면 `나는`으로 시작하는 모든 데이터를 검색하기 위한 쿼리문은 인덱스의 혜택을 전혀 받지 못하게 된다. 이러한 이유로 데이터베이스의 인덱스에서는 B+Tree가 일반적으로 사용된다.
		- B+Tree
			- 범위 검색, 정렬된 탐색에 유리
			- B+Tree는 DB 인덱스를 위해 자식 노드가 2개 이상인 B-Tree를 개선시킨 자료구조이다. B+Tree는 모든 노드에 데이터(Value)를 저장했던 B-Tree와 다른 특성을 가지고 있다.
				- 리프노드(데이터노드)만 인덱스와 함께 데이터(Value)를 가지고 있고, 나머지 노드(인덱스 노드)들은 데이터를 위한 인덱스(Key)만을 갖는다.
				- 리프노드들은 LinkedList로 연결되어 있다.
				- 데이터 노드 크기는 인덱스 노드의 크기와 같지 않아도 된다.
			- 데이터베이스의 인덱스 컬럼은 부등호를 이용한 순차 검색 연산이 자주 발생될 수 있다. 이러한 이유로 B-Tree의 리프노드들은 LinkedList로 연결하여 순차검색을 용이하게 등 B-Tree를 인덱스에 맞게 최적화하였다. (물론 Best Case)에 대해 리프노드까지 가지 않아도 탐색할 수 있는 B-Tree에 비해 무조건 리프노드까지 가야한다는 단점도 있다.)
			- 이러한 이유로 비록 B+Tree는 O(log2n)의 시간복잡도를 갖지만 해시테이블보다 인덱싱에 더욱 적합한 자료구조가 되었다.
			- InnoDB에서 사용된 B + Tree 구조![[Pasted image 20250601194715.png]]
			- InnoDB에서의 B+Tree는 일반적인 구조보다 더욱 복잡하게 구현이 되었다. InnoDB에서는 같은 레벨의 노드들끼리는 Linked List가 아닌 Double Linked List로 연결되었으며, 자식 노드들은 Single Linked List로 연결되어 있다.
	- 인덱스의 장점
		- 테이블을 조회하는 속도와 그에 따른 성능을 향상 시킬 수 있다.
		- 전반적인 시스템의 부하를 줄일 수 있다.
	- 인덱스의 단점
		- 저장 공간 사용
			- 인덱스를 관리하기 위해 DB의 약 10%에 해당하는 저장공간이 필요하다.
		- 쓰기 성능 저하
			- INSERT/UPDATE/DELETE 시 인덱스도 같이 갱신해야 해서 느려질 수 있다.
		- 너무 많으면 역효과
			- 필요한 컬럼에만 걸어야 효율적이다.
	- 인덱스의 관리
		- DBMS는 index를 항상 최신의 정렬된 상태로 유지해야 원하는 값을 빠르게 탐색할 수 있다.
		- 그렇기 때문에 인덱스가 적용된 컬럼에 INSERT, UPDATE, DELETE가 수행된다면 각각 다음과 같은 연산을 추가적으로 해주어야 하며 그에 따른 오버헤드가 발생한다.
		- INSERT
			- 새로운 데이터에 대한 인덱스를 추가
		- UPDATE
			- 삭제하는 데이터의 인덱스를 사용하지 않는다는 작업을 진행함
		- DELETE
			- 기존의 인덱스를 사용하지 않음 처리하고, 갱신된 데이터에 대해 인덱스를 추가함
	- 인덱스를 사용하면 좋은 경우
		- 규모가 작지 않은 테이블
		- INSERT, UPDATE, DELETE가 자주 발생하지 않는 칼럼
		- JOIN이나 WHERE 또는 ORDER BY에 자주 사용되는 칼럼
		- 데이터의 중복도가 낮은 칼럼
		- 기타 등등
		- 인덱스를 사용하는 것 만큼 생성된 인덱스를 관리해주는 것도 중요하다 그러므로 사용되지 않는 인덱스는 바로 제거를 해주어야 한다.
	
- DTO collect 방식 > map으로 수정한 이유는 무엇인가?
	- 
- DTO 최적화 구조는 무엇인가요?
- LazeLoading이란 무엇인가요?
- 
- DB slow query가 무엇인가?
- 로드밸런싱이란 무엇인가?
- application.yml의 hikari, apache tomcat server 설정에 대해 설명해주세요
	- hikari:  
		  maximum-pool-size: 400  
		  minimum-idle: 20  
		  idle-timeout: 10000   
		  max-lifetime: 30000 
	- server:  
		  tomcat:  
		    threads:  
		      max: 2000   
		    accept-count: 3000   
		    connection-timeout: 30000 
	
- DB conection pool이란 무엇인가?
- 요청 대기 큐를 왜 사용하였는가?
- jmeter 테스트 결과 분석을 어떻게 하였고, 원인을 어떻게 추정하였는가?
	- 원인 분석 방법
		- summary report - 평균요청시간, 초당응답률, 에러율을 분석
		- SpringBoot log를 통해 발생한 에러 확인
		- Jmeter - view reulst tree의 response data (request body)의 에러 확인
		- 각 에러에 대한 search, 평균 요청시간 낮추기, 초당 응답율 높이기, 에러율 낮추기 위한 search
- 원인은 무엇이었는가?
	- failed: Connection refused: connect
	- 로그인 요청시간이 너무 길다.
	- 
- 문제해결에 대한 어떤 방법을 사용하였는가?
- 

- 원인
	- DB Index 
	- DTO 변환 작업이 무겁고 반복적
	- DB 커넥션 고갈
	- API 서버 단일 인스턴스 병목
	- Nginx proxy 설정 미흡
	- JMV 튜닝 미흡

- summary report (average, tps, errors)
	1. 1349, 195, 36%
	2. 1159, 196, 28%
	3. 1019, 195, 14%
	4. 1365, 194, 24%
	5. 979, 195, 18% - 4000, 5000, 30000 / 500, 30, 20000, 40000

- 로드밸런싱 - nginx
- https://12bme.tistory.com/366




---
