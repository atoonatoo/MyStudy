
---

---
##### 1. 부하 테스트 설계와 도구 선정
- **k6**
    - **목적**
        - 코드로 작성하고, CLI에서 실행하는 개발자 친화적 테스트 도구
    - **동작 원리**
        - JavaScript 테스트 스크립트 작성
        - k6 런타임이 스크립트를 해석
        - 가상 사용자(VU)를 Go루틴(goroutine)으로 생성
        - 각 VU가 HTTP 요청을 병렬 실행하고 메트릭 수집
    - **장점**
        - 높은 성능 효율
            - Go 기반, 경량 VU 모델 -> 동일 자원 대비 높은 동시성
        - 자동화, CI/CD 친화적
            - CLI 중심 -> Git, CI 파이프라인에 바로 연결
        - 뛰어난 재현성
        - GUI 클릭이 아닌 코드 -> 테스트 조건이 항상 동일
    - **단점**
        - 비개발자 진입 장벽
            - GUI 없음, Javascript 필수
        - 복잡한 시나리오 가시성 부족
            - Jmeter처럼 플로우를 시각적으로 보며 설계하기 어려움
        - 프로토콜 확장 제한
            - HTTP 중심, 특수 프로토콜은 확장 필요
    - **한 문장 기억 공식**
        - k6는 GUI 중심 설계를 채택하지 않고 JavaScript와 Go 기반을 선택해, 빠르고 자동화에 강하지만 개발자 중심으로 설계된 부하 테스트 도구다.
    - **장단점 연결 기억법**
        - 왜 빠른가? -> Go + goroutine
        - 왜 자동화에 강한가? -> CLI + 코드 기반
        - 왜 불편한가? -> GUI 없음
        - 왜 Jmeter와 성격이 다른가? -> 설계 철학이 다름
      
- **JMeter**
    - **목적**
        - JMeter는 GUI로 복잡한 부하 테스트 시나리오를 설계 및 실행하기 위한 범용 테스트 도구이다.
    - **동작 원리**
        - GUI에서 Test Plan 구성
        - Thread Group이 Thread 단위로 가상 사용자 생성
        - Sampler가 요청을 실행
        - Listener가 결과를 수집 및 시각화
    - **장점**
        - 복잡한 시나리오 설계에 강함
            - 조건 분기, 반복, 컨트롤러 구조를 시각적으로 조립 가능
        - 프로토콜 지원 범위가 넓음
            - HTTP, JDBC, FTP, JMS 등 다양한 프로토콜 지원
        - 비개발자도 접근 가능
            - 코드 작성 없이 테스트 구성 가능
    - **단점**
        - 고부하 시 자원 소모 큼
            - Java Thread 모델 -> 메모리, CPU 사용량 증가
        - GUI 실행 시 성능 왜곡 위험
            - Listener, GUI 렌더링이 부하 테스트 결과에 영향
        - 자동화 및 버전 관리의 불리함
            - GUI 기반 설정은 코드 기반 도구보다 재현성이 낮음
    - **한 문장 기억 공식**
        - JMeter는 GUI와 Java Thraed를 선택해 복잡한 시나리오에 강하지만, 대규모 부하와 자동화에는 불리한 도구이다.
    - **장단점 연결 기억법**
        - 왜 시나리오가 강한가?  -> GUI + 컨트롤러 구조
        - 왜 무거운가?  -> Java Thread 기반
        - 왜 CLI 실행이 권장되는가?  -> GUI 성능 간섭 제거
        - 왜 k6와 다르게 쓰는가?  -> 목표 사용자가 다름
      
- **nGrinder**
    - **목적**
        - 웹 UI로 분산 부하 테스트를 쉽게 운영하기 위한 엔터프라이즈용 도구
    - **동작 원리**
        - Controller에서 테스트 시나리오 관리 (웹 UI)
        - 테스트 실행 시 Agent 여러 대에 작업 분배
        - Agent 내부에서 Grinder 엔진 + Jython/Groovy 스크립트 실행
        - 각 Agent의 결과를 Controller가 수집 및 통합
    - **장점**
        - 대규모 분산 부하 테스트에 유리
            - Agent를 수평 확장하여 부하 생성 가능
        - 웹 UI 기반 관리 편의성
            - 테스트 실행, 모니터링, 결과 확인을 한 화면에서 처리
        - 조직 단위 운영에 적합
            - 테스트 이력, 사용자 관리, 권한 관리 제공
    - **단점**
        - 구성 복잡도 높음
            - Controller, Agent, 네트워크 설정 필요
        - 스크립트 작성 난이도
            - Jython/Groovy 기반 -> Java 계열 이해 필요
        - 경량 테스트에는 과함
            - 단일 서버, 간단한 테스트에는 오버엔지니어링
    - **한 문장 기억 공식**
        - nGrinder는 중앙 Controller와 분산 Agent를 선택해 대규모 부하에는 강하지만, 설정과 운영이 무거운 도구이다.
    - **장단점 연결 기억법**
        - 왜 대규모에 강한가?  -> 분산 Agent 구조
        - 왜 운영이 편한가?  -> 웹 UI + 중앙 관리
        - 왜 복잡한가?  -> Controller - Agent 인프라 필요
        - 왜 개인 프로젝트에는 과한가?  -> 엔터프라이즈 지향 설계
      
- **Locust**
    - **목적**
        - Python 코드로 사용자 행동을 자연스럽게 표현하는 분산 부하 테스트 도구이다.
    - **동작 원리**
        - Python으로 사용자 행동(User behavior) 정의
        - Master 노드가 테스트를 제어
        - 여러 Worker 노드가 가상 사용자 실행
        - 결과를 Master에서 실시간 집계 및 웹 UI로 표시
    - **장점**
        - 사용자 행동 표현력이 뛰어남
            - Python 코드로 조건, 상태, 흐름을 자유롭게 표현
        - 분산 부하 테스트 용이
            - Worker 수평 확장으로 부하 증가 가능
        - 실시간 모니터링
            - 웹 UI에서 요청 수, 응답 시간, 실패율을 즉시 확인
    - **단점**
        - Python 성능 한계
            - 고부하에서는 CPU 사용량 증가, 효율성 k6 대비 낮음
        - 완전한 자동화에는 추가 작업 필요
            - 웹 UI 중심 -> CI 환경에선 설정 필요
        - 엔터프라이즈 기능 부족
            - 권한 관리, 테스트 이력 관리 등은 제한적
    - **한 문장 기억 공식**
        - Lucst는 Python으로 사용자 행동을 자연스럽게 표현하는 대신, 극단적인 성능 효율은 포기한 부하 테스트 도구이다.
    - **장단점 연결 기억법**
        - 왜 시나리오가 자연스러운가? -> Python 코드 기반
        - 왜 분산이 쉬운가? -> Master-Worker 구조
        - 왜 성능이 k6보다 약한가? -> Python 런타임
        - 왜 개발자가 선호하는가? -> 학습 비용 낮음

##### 2. 트래픽 부하 분산을 위한 로드 밸런서 구축
- **nginx**
    - **목적**
        - 동시 접속 문제를 해결하기 위해 이벤트 기반 비동기 구조를 선택한 웹 서버
    - **동작 원리**
        - Master Process가 설정 로드 및 Worker 관리
        - 여러 Worker Process가 요청 처리
        - 각 Worker는 이벤트 기반(event-driven)으로 요청 처리
        - 비동기 방식으로 다수의 연결을 단일 스레드에서 처리
    - **장점**
        - 매우 높은 동시 처리 성능
            - 하나의 Worker가 수천 개 연결 처리 가능
        - 낮은 메모리 사용량
            - Thread를 무한히 생성하지 않음
        - 정적 파일 처리에 매우 강함
            - 웹서버, 리버스 프록시로 탁월
    - **단점**
        - 동적 처리 로직에 부적합
            - 애플리케이션 로직 직접 처리 불가(PHP, Java 등은 외부 연동)
        - 구성 난이도
            - 설정 파일이 선언적이고 복잡하게 느껴질 수 있다.
        - Worker 수 설정 실패 시 성능 저하
            - CPU 코어 수 대비 Worker 설정 중요
    - **한 문장 기억 공식**
        - Nginx는 요청당 Thread를 생성하지 않고 이벤트 기반 비동기 모델을 선택해, 동시성에는 강하지만 애플리케이션 서버 역할은 하지 않는다.
    - **장단점 연결 기억법**
        - 왜 빠른가? -> 이벤트 기반 비동기
        - 왜 메모리를 적게 쓰는가? -> Thread 미사용
        - 왜 WAS가 필요한가? -> 로직 처리 불가
        - 왜 로드밸런서로 쓰는가? -> 연결 처리 전문
    
- **HAProxy**
    - **목적**
        - 고가용성과 초고성능 트래픽 분산을 위해 만들어진 전문 로드 밸런서
    - **동작 원리**
        - Frontend가 클라이언트 연결 수신
        - Backend에 등록된 서버 풀로 트래픽 분산
        - 이벤트 기반 비동기 방식으로 연결 처리
        - Helth Check로 비정상 서버 자동 제외
    - **장점**
        - 매우 높은 처리량과 낮은 지연
            - 네트워크 레벨에서 최적화된 처리
        - 정교한 트래픽 제어
            - ACL, 라우팅, 가중치, 세션 유지 등 강력
        - 고가용성 지원
            - 헬스 체크 기반 장애 대응
    - **단점**
        - 웹 서버 기능 부재
            - 정적 파일 제공 불가
        - 설정 난이도
            - ACL, Backend 설정이 복잡
        - 가시성은 기본 수준
            - UI보다 로그, 메트릭 중심
    - **한 문장 기억 공식**
        - HAProxy는 웹 서버 기능을 포함하지 않는 대신, 트래픽 분산과 고가용성에 특화된 로드 밸런서이다.
    - **장단점 연결 기억법**
        - 왜 빠른가? -> 네트워크 최적화
        - 왜 안정적인가? -> Health Check
        - 왜 Nginx와 다른가? -> 웹 서버 기능 없음
        - 왜 대규모 트레픽에 쓰는가? -> 전문화된 역할
    
- **AWS ALB**
    - **목적**
        - 애플리케이션 계층(L7)에서 트래픽을 지능적으로 분산하기 위한 관리형 로드 밸런서
    - **동작 원리**
        - Listener가 HTTP/HTTPS 요청 수신
        - 요청의 Host, Path, Header, Query 조건 평가
        - Rule에 따라 대상 Target Group 선택
        - Target Group 내 Target(EC2, ECS, IP, Lambda)으로 전달
    - **장점**
        - 지능적인 라우팅
            - URL, Host 기반 라우팅으로 마이크로서비스에 최적
        - 운영 부담 최소화
            - 서버 설치, 패치, 확장 모두 AWS가 관리
        - AWS 서비스와 깊은 통합
            - ECS, EKS, Lambda, Auto Scaling과 자연스럽게 연동
    - **단점**
        - L4 로드 밸런싱 불가
            - TCP/UDP 레벨의 트래픽 제어는 불가능 (NLB 필요)
        - 벤더 종속성
            - AWS 환경 외부에서는 사용 불가
        - 세밀한 커스터마이징 한계
            - HAProxy 수준의 저수준 제어는 어려움
    - **한 문장 기억 공식**
        - AWS ALB는 인프라 운영 책임을 AWS에 위임하는 대신, 애플리케이션 계층(L7) 트래픽 분산을 자동화한 관리형 로드 밸런서이다.
    - **장단점 연결 기억법**
        - 왜 편한가? -> Magend Service
        - 왜 마이크로서비스에 강한가? -> L7 Rule 기반 라우팅
        - 왜 저수준 제어가 안되는가? -> AWS가 내부를 숨김
        - 왜 NLB와 나뉘는가? -> 계층 분리 설계
    
- **Treafik**
    - **목적**
        - 서비스 디스커버리를 기반으로 설정 없이 자동 라우팅하는 클라우드 네이티브 프록시
    - **동작 원리**
        - Provider(Docker, Kubernetes, Consul 등)에서 서비스 변화 감지
        - 메타데이터(Label/Annotation)로 라우팅 규칙 자동 생성
        - EntryPoint로 요청 수신
        - Router -> Middleware -> Service 체인으로 트래픽 전달
    - **장점**
        - 설정 자동화
            - 서비스 추가/삭제 시 수동 설정 불필요
        - 컨테이너, Kubernetes 친화
            - Ingress Controller로 자연스럽게 동작
        - 실시간 설정 반영
            - 재시작 없이 라우팅 변경 가능
    - **단점**
        - 전통적 서버 환경에 과함
            - 정적 서버 위주 환경에서는 이점 감소
        - 저수준 트래픽 제어 한계
            - HAProxy 수준의 세밀한 제어는 어려움
        - 추상화로 인한 디버깅 난이도
            - 자동화된 라우팅 흐름 파악이 어려울 수 있음
    - **한 문장 기억 공식**
        - Treafik은 수동 설정 보다 서비스 디스커버리를 선택해, 클라우드 환경에서 편하지만 전통 환경에선 과한 프록시이다.
    - **장단점 연결 기억법**
        - 왜 설정이 거의 없는가? -> Provider 기반 자동 탐지
        - 왜 Kubernetes에 강한가? -> Ingress Native 설계
        - 왜 세밀한 제어가 약한가? -> 고수준 추상화
        - 왜 Nginx/HAProxy와 다른가? -> 운영 철학 차이
    

##### 3. 중앙 집중형 로그 수집기 설계 및 시각화 환경 구축
###### 3.1 로그 저장소 비교 및 선정
- **Elasticsearch**
    - **목적**
        - 대규모 데이터를 빠르게 검색, 집계, 분석하기 위한 분산 검색 엔진
        - RDB를 대체하는 것이 아니라, 텍스트 검색과 실시간 분석을 보완하기 위한 시스템
    - **동작 원리**
        - 문서를 JSON 형태로 저장
        - 문서의 텍스트 필드를 분석기(analyzer)로 토큰화
        - 토큰을 역색인(inverted index) 구조로 저장
        - 검색 시 역색인을 통해 관련 문서 ID를 빠르게 조회
        - 여러 노드에 Shard로 분산 저장 및 처리
    - **장점**
        - 매우 뛰어난 검색 성능
            - 역색인 구조로 대량 텍스트 검색에 최적
        - 수평 확장이 쉬움
            - 샤드 단위 분산으로 노드 추가만으로 확장 가능
        - 강력한 집계(aggregation) 기능
            - 로그 분석, 통계, 대시보드에 적합
        - 스키마 유연성
            - 명시적 스키마 없이도 데이터 적재 가능
    - **단점**
        - 강한 트랜잭션(ACID) 미지원
            - RDB 수준의 트랜잭션, 조인, 롤백 불가
        - 데이터 정합성 관리 부담
            - Near Real-Time 특성으로 즉시 일관성 보장 아님
        - 높은 운영 난이도
            - 메모리, 샤드 수, 인덱스 설계에 따라 성능 급변
        - 저장소로만 사용하기엔 비효율
            - 단순 CRUD 용도로는 과한 비용
    - **한 문장 기억 공식**
        - Elasticsearch는 역색인 기반으로 검색과 분석에 특화된 분산 엔진이며, 트랜잭션 처리를 목적으로 설계된 시스템은 아니다.
    - **장단점 연결 기억법**
        - 왜 검색이 빠른가? ->역색인 구조
        - 왜 확장이 쉬운가? -> 샤드 기반 분산 설계
        - 왜 트랜잭션이 약한가? -> ACID가 설계 목표가 아님
        - 왜 로그, 검색에 쓰는가? -> 검색 + 집계가 핵심 역할
    
- **OpenSearch**
    - **목적**
        - 오픈 소스 기반의 분산 검색, 분석 엔진
        - Elasticsearch의 오픈소스 사용 제약 변화 이후, 완전한 오픈소스 대안으로 유지 및 발전시키는 것이 목적
    - **동작 원리**
        - 문서를 JSON 형태로 인덱스에 저장
        - 텍스트 필드를 분석기(analyzer)로 토큰화
        - Lucene 기반 역색인(inverted index) 생성
        - 인덱스를 shard로 분할하여 여러 노드에 분산
        - 검색, 집계 요청을 각 샤드에서 병렬 처리 후 결과 병합
    - **장점**
        - 완전한 오픈 소스
            - Apach 2.0 라이선스
            - 기능 사용에 라이선스 제약 없음
        - Elasticsearch와 높은 호환성
            - 기존 Elasticsearch 사용자 이전 비용 낮춤
        - 검색 및 집계 성능 우수
            - 역색인 + 분산 처리 구조 유지
        - 플러그인 확장성
            - 보안, 알림, SQL 등 오픈 플러그인 제공
    - **단점**
        - Elasticsearch 대비 생태계 규모 작음
            - 상용 솔루션, 서드파티 연동은 상대적으로 적음
        - 기능 발전 속도는 커뮤니티 의존적
            - Elastic 상용 기능과 동일한 속도로 따라가지는 못함
        - 운영 복잡도는 동일
            - 샤드 수, 메모리, 인덱스 설계에 따라 성능 크게 좌우우
    - **한 문장 기억 공식**
        - OpenSearch는 Elasticsearch에서 파생된, 역색인 기반 검색 및 분석에 특화된 완전 오픈 소스 분산 엔진이다.
    - **장단점 연결 기억법**
        - 왜 Elasticsearch와 비슷한가? -> Lucene + 동일한 기본 아키텍처
        - 왜 이전이 쉬운가? -> API, 개념 호환성
        - 왜 비용 부담이 적은가? -> Apache 2.0 라이선스
        - 왜 운영이 어려운가? -> 분산 샤드 구조는 동일
    
- **Grafana Loki**
    - **목적**
    - **동작 원리**
    - **장점**
    - **단점**
    - **한 문장 기억 공식**
    - **장단점 연결 기억법**
    
- **Graylog**
    - **목적**
    - **동작 원리**
    - **장점**
    - **단점**
    - **한 문장 기억 공식**
    - **장단점 연결 기억법**

###### 3.2 로그 수집기 비교 및 선정
- 
    - **목적**
    - **동작 원리**
    - **장점**
    - **단점**
    - **한 문장 기억 공식**
    - **장단점 연결 기억법**
    
- 
    - **목적**
    - **동작 원리**
    - **장점**
    - **단점**
    - **한 문장 기억 공식**
    - **장단점 연결 기억법**
    
- 
    - **목적**
    - **동작 원리**
    - **장점**
    - **단점**
    - **한 문장 기억 공식**
    - **장단점 연결 기억법**
    
- 
    - **목적**
    - **동작 원리**
    - **장점**
    - **단점**
    - **한 문장 기억 공식**
    - **장단점 연결 기억법**
###### 3.3 시각화 및 모니터링 도구 비교 및 선정
- 
    - **목적**
    - **동작 원리**
    - **장점**
    - **단점**
    - **한 문장 기억 공식**
    - **장단점 연결 기억법**
    
- 
    - **목적**
    - **동작 원리**
    - **장점**
    - **단점**
    - **한 문장 기억 공식**
    - **장단점 연결 기억법**
    
- 
    - **목적**
    - **동작 원리**
    - **장점**
    - **단점**
    - **한 문장 기억 공식**
    - **장단점 연결 기억법**
    
- 
    - **목적**
    - **동작 원리**
    - **장점**
    - **단점**
    - **한 문장 기억 공식**
    - **장단점 연결 기억법**


##### 2.
- 
    - **목적**
    - **동작 원리**
    - **장점**
    - **단점**
    - **한 문장 기억 공식**
    - **장단점 연결 기억법**
    
- 
    - **목적**
    - **동작 원리**
    - **장점**
    - **단점**
    - **한 문장 기억 공식**
    - **장단점 연결 기억법**
    
- 
    - **목적**
    - **동작 원리**
    - **장점**
    - **단점**
    - **한 문장 기억 공식**
    - **장단점 연결 기억법**
    
- 
    - **목적**
    - **동작 원리**
    - **장점**
    - **단점**
    - **한 문장 기억 공식**
    - **장단점 연결 기억법**

##### 2.
- 
    - **목적**
    - **동작 원리**
    - **장점**
    - **단점**
    - **한 문장 기억 공식**
    - **장단점 연결 기억법**
    
- 
    - **목적**
    - **동작 원리**
    - **장점**
    - **단점**
    - **한 문장 기억 공식**
    - **장단점 연결 기억법**
    
- 
    - **목적**
    - **동작 원리**
    - **장점**
    - **단점**
    - **한 문장 기억 공식**
    - **장단점 연결 기억법**
    
- 
    - **목적**
    - **동작 원리**
    - **장점**
    - **단점**
    - **한 문장 기억 공식**
    - **장단점 연결 기억법**

##### 2.
- 
    - **목적**
    - **동작 원리**
    - **장점**
    - **단점**
    - **한 문장 기억 공식**
    - **장단점 연결 기억법**
    
- 
    - **목적**
    - **동작 원리**
    - **장점**
    - **단점**
    - **한 문장 기억 공식**
    - **장단점 연결 기억법**
    
- 
    - **목적**
    - **동작 원리**
    - **장점**
    - **단점**
    - **한 문장 기억 공식**
    - **장단점 연결 기억법**
    
- 
    - **목적**
    - **동작 원리**
    - **장점**
    - **단점**
    - **한 문장 기억 공식**
    - **장단점 연결 기억법**

##### 2.
- 
    - **목적**
    - **동작 원리**
    - **장점**
    - **단점**
    - **한 문장 기억 공식**
    - **장단점 연결 기억법**
    
- 
    - **목적**
    - **동작 원리**
    - **장점**
    - **단점**
    - **한 문장 기억 공식**
    - **장단점 연결 기억법**
    
- 
    - **목적**
    - **동작 원리**
    - **장점**
    - **단점**
    - **한 문장 기억 공식**
    - **장단점 연결 기억법**
    
- 
    - **목적**
    - **동작 원리**
    - **장점**
    - **단점**
    - **한 문장 기억 공식**
    - **장단점 연결 기억법**

##### 2.
- 
    - **목적**
    - **동작 원리**
    - **장점**
    - **단점**
    - **한 문장 기억 공식**
    - **장단점 연결 기억법**
    
- 
    - **목적**
    - **동작 원리**
    - **장점**
    - **단점**
    - **한 문장 기억 공식**
    - **장단점 연결 기억법**
    
- 
    - **목적**
    - **동작 원리**
    - **장점**
    - **단점**
    - **한 문장 기억 공식**
    - **장단점 연결 기억법**
    
- 
    - **목적**
    - **동작 원리**
    - **장점**
    - **단점**
    - **한 문장 기억 공식**
    - **장단점 연결 기억법**


